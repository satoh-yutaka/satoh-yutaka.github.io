<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>佐藤 雄隆 博士（工学）（Yutaka Satoh, Ph.D.）</title>
  <style>
    :root {
      --bg-color: #ffffff;
      --text-color: #222222;
      --accent-color: #007acc;
      --secondary-color: #555555;
      --degree-color: #444444;
      --transition-speed: 0.3s;
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
        padding-left: 2rem;
        padding-right: 2rem;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      color: var(--text-color);
      background: var(--bg-color);
      min-height: 100vh;
    }
    /* Header with Banner and Last Updated */
    header {
      position: fixed; top: 0; left: 0;
      width: 100%; background: var(--bg-color);
      border-bottom: 1px solid #e0e0e0; z-index: 1000;
    }
    .header-inner {
      max-width: 960px; margin: 0 auto;
      padding: 0.5rem 1rem;
      display: flex; align-items: center; justify-content: space-between;
    }
    .site-banner { display: block; height: 60px; object-fit: contain; }
    .last-updated {
      font-size: 0.875rem;
      color: var(--secondary-color);
    }

    /* Content (padding for header only) */
    .content {
      max-width: 960px; margin: 0 auto;
      padding: 120px 1rem 2rem;
    }
    section { margin-bottom: 4rem; }
    section h2 {
      font-size: 1.75rem; margin-bottom: 1rem;
      border-bottom: 2px solid var(--accent-color);
      display: inline-block; padding-bottom: 0.25rem;
    }

    /* Profile Section */
    .profile-section {
      display: flex; flex-wrap: wrap; gap: 2rem;
      align-items: center; margin-bottom: 4rem;
    }
    .profile-pic { flex: 0 0 180px; max-width: 180px; border-radius: 50%; overflow: hidden; }
    .profile-pic img { width: 100%; height: auto; display: block; }
    .profile-info { flex: 1; }

    /* Name styling */
    .profile-name {
      font-size: 1.4rem;
      font-weight: 600;
      color: var(--text-color);
      margin-bottom: 0.5rem;
      line-height: 1.2;
    }
    /* Degree styling: slightly smaller */
    .profile-degree {
      font-size: 0.85em;
      color: var(--degree-color);
    }
    .affiliation {
      font-size: 1rem; color: var(--secondary-color); margin-bottom: 1rem;
    }
    .profile-info p:not(.profile-name):not(.affiliation) { margin-bottom: 0.75rem; }

    /* Responsive */
      @media (max-width: 768px) {
        .content { padding-top: 100px; }
        .profile-section { flex-direction: column; text-align: center; }
        .header-inner { flex-direction: column; text-align: center; gap: 0.5rem; }
        /* Themes & Key Papers mobile wrap */
        #themes table { flex-wrap: wrap; }
        #themes table td[align="right"] { flex: 1 1 100%; width: 100%; margin-top: 1rem; }
      }
      /* Themes & Key Papers Table Flex Layout */
      #themes table {
        display: flex;
        justify-content: space-between;
        width: 100%;
        border: none;
      }
      #themes table tr { display: flex; width: 100%; }
      #themes table td[valign="top"] {
        flex: 1;
        padding-right: 1rem;
      }
      #themes table td[valign="top"] ul {
        margin-left: 1.5rem;
        list-style-type: disc;
        list-style-position: outside;
        padding-left: 0;
      }
      #themes table td[align="right"] {
        flex: 0 0 200px;
        text-align: center;
      }
      #themes table td[align="right"] img {
        width: 100%;
        border-radius: 0.5rem;
      }
          /* Add spacing between Themes list items */
      #themes table td[valign="top"] ul li {
        margin-bottom: 0.2rem;
      }
    </style>
</head>
<body>
  <header>
    <div class="header-inner">
      <a href="#top"><img src="https://satoh-yutaka.github.io/images/top008.jpg" alt="Banner" class="site-banner"></a>
      <div class="last-updated">Last updated: 2025-04-17</div>
    </div>
  </header>
  <main id="top" class="content">
    <section id="about">
      <div class="profile-section">
        <div class="profile-pic">
          <img src="https://satoh-yutaka.github.io/images/photo-face2.jpg" alt="Satoh, Yutaka">
        </div>
        <div class="profile-info">
          <div class="profile-name">
            佐藤 雄隆， <span class="profile-degree">博士（工学）</span><br>
            Yutaka Satoh, Ph.D.
          </div>
          <div class="affiliation">
            国立研究開発法人産業技術総合研究所<br>
            人工知能研究センター 首席研究員<br>
            Principal Researcher, AIRC, AIST.
          </div>
          <p>
            （兼）筑波大学大学院 理工情報生命学術院<br>
            情報理工学位プログラム 教授（連携大学院）<br>
            Professor, University of Tsukuba.
          </p>
          <p>
            E-mail: &#121;&#117;&#46;&#115;&#97;&#116;&#111;&#117;&#32;&#65;&#84;&#32;&#97;&#105;&#115;&#116;&#46;&#103;&#111;&#46;&#106;&#112;
          </p>
        </div>
      </div>
    </section>

    <!-- ----------------------------------------------------------------- -->
      <section id="topics">
        <h2>Topics</h2>
        <p>
          <img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
          <b><a href="./univ.htm">筑波大学連携大学院「佐藤研究室」</a>では，修士および博士課程の学生を受け入れています．</b>
          産総研の先端的な研究環境で学びつつ<b>筑波大学の学位を取得できます</b>．
          全国の大学・高専（専攻科）等からの受験を歓迎しています．
          詳しくは
          <a href="./univ.htm">
            こちら
          </a>
          をご覧ください．<br><br>

          まずは，&#121;&#117;&#46;&#115;&#97;&#116;&#111;&#117;&#32;&#65;&#84;&#32;&#97;&#105;&#115;&#116;&#46;&#103;&#111;&#46;&#106;&#112; （ATを@に変更して使用してください。）まで遠慮無くご相談下さい．<br>
          <b>Admissions:</b> Cooperative Graduate School Program (master's & doctoral course), University of Tsukuba. Please see <a href="http://www.cs.tsukuba.ac.jp/english/admission.html" target="_blank"> here</a>.<br>

          <br><hr width=80%>
    <!----------------------->
	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
	<b>産総研論文賞2022を受賞しました．</b><br>
	「Pre-training without Natural Images」(IJCV論文)</b>
	<br>
	FY2022 AIST Best paper award<br>

	<a href="https://www.aist.go.jp/aist_j/aist_award/2022/abpa.html#no3" target="_blank">
	→産総研論文賞</a><br>
    <br><hr width=80%>
        
  <!----------------------->
	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
	<b>産総研論文賞2019を受賞しました．</b><br>
	「Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?」(CVPR2018論文)</b>
	<br>
	FY2019 AIST Best paper award<br>

	<a href="https://www.aist.go.jp/aist_j/aist_award/2019/abpa.html#no3" target="_blank">
	→産総研論文賞</a><br>
	<a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.html" target="_blank">→CVPR2018 open access</a><br>
    <br><hr width=80%>

        
    <!----------------------->
	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
	<b>
	プレス発表：「直射日光下でのパターン投影による高速形状計測に成功」
	</b><br>
	キネクトのようなパターン光投影型形状計測を<u>直射日光下でも</u>可能にしました．<br>
	<a href="http://www.aist.go.jp/aist_j/press_release/pr2017/pr20170714/pr20170714.html" target="_blank">→産総研プレスリリース</a><br>
	<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Sagawa_Illuminant-Camera_Communication_to_CVPR_2017_paper.html" target="_blank">→CVPR2017 open access</a><br>
	<b>Press release:</b> Please see <a href="http://www.aist.go.jp/aist_j/press_release/pr2017/pr20170714/pr20170714.html" target="_blank"> here</a> and <a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Sagawa_Illuminant-Camera_Communication_to_CVPR_2017_paper.html" target="_blank"> here</a>.<br>
    <br><hr width=80%>

  <!----------------------->
	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
	<b>
	科学技術分野の文部科学大臣表彰 
	「若手科学者賞」</b>
	を受賞いたしました．
	<br>
	<b>Minister's Prize:</b> The Young Scientists' Prize, The Commendation for Science and Technology by the Minister of Education, Culture, Sports, Science and Technology.<br>

	<a href="http://www.aist.go.jp/aist_j/news/prize/itemid025-000059.html"  target="_blank">
	→受賞</a>
      
        </p>
      </section>

    <!-- ----------------------------------------------------------------- -->
    <section id="keywords">
      <h2>Research Keywords</h2>
      <p>
        <img src="https://satoh-yutaka.github.io/images/check_mark_s.png">	
    	コンピュータビジョン - computer vision systems<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	画像認識・理解 - image recognition and understanding<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	動画像認識 - video recognition<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	パターン認識 - pattern recognition<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	機械学習 - machine learning<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	ディープラーニング - Deep Learning<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	画像特徴抽出 - image feature extraction<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	ロバスト画像処理 - robust image processing<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	三次元画像取得・処理 - 3D imaging<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	全方向ステレオカメラ - stereo omni-directional camera system<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	ロボットビジョン - robot vision systems<br>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">        
    	VR/MR/AR - Virtual Reality systems<br>
      </p>
    </section>

    <!-- ----------------------------------------------------------------- -->
    <section id="themes">
      <h2>Themes &amp; Key Papers</h2>
      <p>
    	<img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
    	<b><u>全文献リストは<a href="https://scholar.google.co.jp/citations?user=Ti3ctdAAAAAJ" target="_blank">こちら</a>，Paper list is <a href="https://scholar.google.co.jp/citations?user=Ti3ctdAAAAAJ" target="_blank">here</a>.</u></b>
      <!----------------------->

    	<br><br>
        <img src="https://satoh-yutaka.github.io/images/check_mark_s.png">
    	<b>DNNを活用した静止画像／動画像解析（2014～）</b><br>
    	Deep Neural Network based Image / Video Analysis
    	<br><br>
    	<table width=100% border=0 cellspacing=0 cellpadding=0>
    	<tr>
    	<td valign="top">
    	<ul>
    
    	<li>R Yamada, K Hara, H Kataoka, K Makihara, N Inoue, R Yokota, Y Satoh, 
    	"Formula-Supervised Visual-Geometric Pre-training", 
    	Proceedings of the European Conference on Computer Vision (ECCV2024), 
    	pp.57-74, 2024.
    
    	<li>Fumiya Matsuzawa, Yue Qiu, Yanjun Sun, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh, 
    	Subtle-Diff: A Dataset for Precise Recognition of Subtle Differences Among Visually Similar Objects, 
    	Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), 
    	pp.5888-5894, 2024.
    
    	<li>Fumiya Matsuzawa, Yue Qiu, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh, 
    	"Question Generation for Uncertainty Elimination in Referring Expressions in 3D Environments", 
    	Proceedings of the IEEE International Conference on Robotics and Automation (ICRA2023), 
    	pp.6146-6152, 2023.
    
    	<li>K Nakashima, H Kataoka, A Matsumoto, K Iwata, N Inoue, Y Satoh, 
    	"Can vision transformers learn without natural images?", 
    	Proceedings of the AAAI Conference on Artificial Intelligence (AAAI2022), 
    	36 (2), pp.1990-1998, 2022.
    
    	<li>Kataoka Hirokatsu, Matsumoto Asato, Yamagata Eisuke, Yamada Ryosuke, Inoue Nakamasa, Akio Nakamura, Satoh Yutaka, 
    	"Pre-training without natural images", 
    	International Journal of Computer Vision (IJCV), 
    	130 (4), pp.990-1007, 2022.
    	<br><font color="#990000" size=-1 >Award: 産総研論文賞2022</font><br>
    
    	<li>Kensho Hara, Hirokatsu Kataoka, Masaki Inaba, Kenichi Narioka, Ryusuke Hotta, Yutaka Satoh, 
    	"Predicting appearance of vehicles from blind spots based on pedestrian behaviors at crossroads", 
    	IEEE transactions on intelligent transportation systems, 23 (8), 
    	pp.11917-11929, 2021
    
    	<li>Yue Qiu, Shintaro Yamamoto, Kodai Nakashima, Ryota Suzuki, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh, 
    	"Describing and localizing multiple changes with transformers", 
    	Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV2021), 
    	pp.1971-1980, 2021.
    
    	<li>Hirokatsu Kataoka, Teppei Suzuki, Kodai Nakashima, Yutaka Satoh, Yoshimitsu Aoki, 
    	"Joint pedestrian detection and risk-level prediction with motion-representation-by-detection", 
    	Proceedings of the IEEE International Conference on Robotics and Automation (ICRA2020), 
    	pp.1021-1027, 2020.
    
    	<li>Hirokatsu Kataoka, Kazushige Okayasu, Asato Matsumoto, Eisuke Yamagata, Ryosuke Yamada, Nakamasa Inoue, Akio Nakamura, Yutaka Satoh, 
    	Pre-training without natural images, 
    	Proceedings of the Asian Conference on Computer Vision (ACCV2020),
    	2020.
    	<br><font color="#990000" size=-1 >Award: ACCV 2020 Best Paper Honorable Mention Award</font><br>
    
    	<li>Hirokatsu Kataoka, Yutaka Satoh, 
    	"Unsupervised out-of-context action understanding", 
    	Proceedings of the IEEE International Conference on Robotics and Automation (ICRA2019), 
    	pp.8227-8233, 2019.
    
    	<li>相澤宏旭,片岡裕雄,佐藤雄隆,加藤邦人, 
    	Viewpoint-agnostic Image Rendering, 
    	第25回画像センシングシンポジウム(SSII2019)講演論文集, 
    	2019.
    	<br><font color="#990000" size=-1 >Award: 画像センシングシンポジウム優秀学術賞</font><br>
    
    	<li>Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh，
    	<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.pdf" target="_blank">
    	"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet ?"，
    	Proc. Conference on Computer Vision and Pattern Recognition (CVPR2018)</a>
    	，pp.6546-6555，2018．
    	*** 
    	<a href="https://github.com/kenshohara/3D-ResNets-PyTorch" target="_blank">
    	GitHub (4K+ stars !)
    	</a>
    	<br><font color="#990000" size=-1 >Award: 産総研論文賞2019</font><br>
    
    	<li>Tomoyuki Suzuki, Hirokatsu Kataoka, Yoshimitsu Aoki, Yutaka Satoh，
    	<a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0494.pdf" target="_blank">
    	"Anticipating Traffic Accidents with Adaptive Loss and Large-scale Incident DB"，
    	Proc. Conference on Computer Vision and Pattern Recognition (CVPR2018)
    	</a>
    	，pp.3521-3529，2018．<br>
    
    	<li>Hirokatsu Kataoka, Teppei Suzuki, Shoko Oikawa, Yasuhiro Matsui, Yutaka Satoh，
    	"Drive Video Analysis for the Detection of Traffic Near-Miss Incidents"，
    	Proc. IEEE International Conference on Robotics and Automation (ICRA2018)，pp.3421-3428，2018.<br>
    
    	<li>Hirokatsu Kataoka, Yudai Miyashita Masaki Hayashi, Kenji Iwata, Yutaka Satoh，
    	"Recognition of Transitional Action for Short-Term Action Prediction using Discriminative Temporal CNN Feature"，
    	Proc. of British Machine Vision Conference (BMVC2016)，Online，2016．<br>
    
    	<li>Hirokatsu Kataoka, Yoshimitsu Aoki, Yutaka Satoh, Shoko Oikawa, Yasuhiro Matsui ，
    	"Fine-grained Walking Activity Recognition via Driving Recorder Dataset"，
    	Proc. of 2015 IEEE 18th International Conference on Intelligent Transportation Systems (ITSC2015)，pp.620-625，2015．<br>
    
    	<!--
    	<li>Hirokatsu Kataoka, Yutaka Satoh, Yoshimitsu Aoki, Masako Oikawa, Yasuhiro Matsui，
    	"Temporal and Fine-Grained Pedestrian Action Recognition on Driving Recorder Database"，
    	SENSORS，Vol.18, No.2，doi: 10.3390/s18020627，2018．<br>
    	-->
    
    	<li>Kensho Hara, Hirokatsu Kataoka, Yutaka Satoh，
    	"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions"，
    	Proc. International Conference on Pattern Recognition (ICPR2018)，pp.2516-2521，2018．<br>
    
    	<!--
    	<li>QIU YUE, 佐藤雄隆，鈴木亮太，片岡裕雄，
    	"多視点を前提とした三次元空間尤度投票型物体認識"，
    	精密工学会論文誌，Vol.83, No.12，pp.1125-1130，2017．<br>
    	-->
    
    	<li>賀 雲,片岡 裕雄,白壁 奏馬,佐藤 雄隆，
    	"人を見ない人物行動認識"，
    	ビジョン技術の実利用ワークショップ(ViEW2016)講演論文集，USB，2016．<br>
    	<font color="#990000" size=-1 >Award: 平成28年精密工学会画像応用技術専門委員会若手奨励賞受賞</font><br>
    
    	<li>Kaori Abe,Teppei Suzuki,Shunya Ueta,Akio Nakamura,Yutaka Satoh,Hirokatsu Kataoka，
    	"Dynamic Fashion Cultures"，
    	Proc. MIRU2017，2017．<br>
    	<font color="#990000" size=-1 >Award: MIRU学生優秀賞受賞</font><br>
    
    	</ul>
    	</td>
    	<td width=10></td>
    
    	<td align=right valign=top width=175>
    	<img src="images/NIDB.png"><br>
    	<center><font size=-1>ドライブレコーダー映像解析</font></center><br>
    	<img src="images/3Dconv.png"><br>
    	<center><font size=-1>3D ResNets for Action Recognition</font></center>
    	</td>
    	</tr>
    	</table>
        
      </p>

    <!-- ----------------------------------------------------------------- -->
    </section>
    <section id="awards">
      <h2>Awards</h2>
      <p>Detail your awards and honors.</p>

    <!-- ----------------------------------------------------------------- -->
    </section>
    <section id="society">
      <h2>Society Activities</h2>
      <p>List professional society roles and memberships.</p>

    <!-- ----------------------------------------------------------------- -->
    </section>
    <section id="academic">
      <h2>Academic Affairs</h2>
      <p>Outline teaching, committee work, and service.</p>
    </section>

    <!-- ----------------------------------------------------------------- -->

  </main>
</body>
</html>
